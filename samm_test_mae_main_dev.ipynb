{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A jupyter notebook version file for the `main.py`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `autoreload` to execute the change in `.py` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = \"D:/Databases/SAMM_longvideos\"\n",
    "# dataset_dir = \"I:/HEH/Databases/SAMM_longvideos\"\n",
    "# dataset_dir = \"/data/disk1/heh/databases/SAMM_longvideos\"\n",
    "\n",
    "test_dataset_dir = \"D:/Databases/MEGC2022_testSet/SAMM_Test_cropped\"\n",
    "# test_dataset_dir = \"I:/HEH/Databases/MEGC2022_testSet/SAMM_Test_cropped\"\n",
    "# test_dataset_dir = \"/data/disk1/heh/databases/MEGC2022_testSet/SAMM_Test_cropped\"\n",
    "\n",
    "images_loading = False\n",
    "image_size = 128\n",
    "load_cropped_images = False\n",
    "# expression_type = \"micro-expression\"\n",
    "expression_type = \"macro-expression\"\n",
    "save_x = False\n",
    "debug_preds = True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing import *\n",
    "\n",
    "# crop_images_dev(test_dataset_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When debug the image processing, the videos_images is from cropped_rawpic, whereas the other variables are from rawpic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_video: 006_1\n",
      "subject_video: 006_2\n",
      "subject_video: 006_3\n",
      "subject_video: 006_4\n",
      "subject_video: 006_5\n",
      "subject_video: 006_6\n",
      "subject_video: 006_7\n",
      "subject_video: 007_3\n",
      "subject_video: 007_4\n",
      "subject_video: 007_5\n",
      "subject_video: 007_6\n",
      "subject_video: 007_7\n",
      "subject_video: 008_1\n",
      "subject_video: 008_5\n",
      "subject_video: 008_6\n",
      "subject_video: 008_7\n",
      "subject_video: 009_2\n",
      "subject_video: 009_3\n",
      "subject_video: 009_4\n",
      "subject_video: 009_6\n",
      "subject_video: 009_7\n",
      "subject_video: 010_1\n",
      "subject_video: 010_2\n",
      "subject_video: 010_3\n",
      "subject_video: 010_4\n",
      "subject_video: 010_5\n",
      "subject_video: 010_6\n",
      "subject_video: 010_7\n",
      "subject_video: 011_1\n",
      "subject_video: 011_2\n",
      "subject_video: 011_3\n",
      "subject_video: 011_4\n",
      "subject_video: 011_5\n",
      "subject_video: 011_6\n",
      "subject_video: 011_7\n",
      "subject_video: 012_3\n",
      "subject_video: 012_4\n",
      "subject_video: 012_5\n",
      "subject_video: 012_6\n",
      "subject_video: 012_7\n",
      "subject_video: 013_1\n",
      "subject_video: 013_2\n",
      "subject_video: 013_3\n",
      "subject_video: 013_6\n",
      "subject_video: 013_7\n",
      "subject_video: 014_1\n",
      "subject_video: 014_2\n",
      "subject_video: 014_3\n",
      "subject_video: 014_4\n",
      "subject_video: 014_5\n",
      "subject_video: 014_6\n",
      "subject_video: 014_7\n",
      "subject_video: 015_1\n",
      "subject_video: 015_3\n",
      "subject_video: 015_5\n",
      "subject_video: 015_6\n",
      "subject_video: 015_7\n",
      "subject_video: 016_1\n",
      "subject_video: 016_2\n",
      "subject_video: 016_4\n",
      "subject_video: 016_5\n",
      "subject_video: 016_6\n",
      "subject_video: 016_7\n",
      "subject_video: 017_1\n",
      "subject_video: 017_2\n",
      "subject_video: 017_3\n",
      "subject_video: 017_4\n",
      "subject_video: 017_5\n",
      "subject_video: 017_6\n",
      "subject_video: 018_1\n",
      "subject_video: 018_2\n",
      "subject_video: 018_3\n",
      "subject_video: 018_4\n",
      "subject_video: 018_5\n",
      "subject_video: 018_6\n",
      "subject_video: 018_7\n",
      "subject_video: 019_1\n",
      "subject_video: 019_2\n",
      "subject_video: 019_3\n",
      "subject_video: 019_4\n",
      "subject_video: 019_5\n",
      "subject_video: 019_7\n",
      "subject_video: 020_1\n",
      "subject_video: 020_2\n",
      "subject_video: 020_3\n",
      "subject_video: 020_4\n",
      "subject_video: 020_5\n",
      "subject_video: 020_6\n",
      "subject_video: 020_7\n",
      "subject_video: 021_3\n",
      "subject_video: 021_7\n",
      "subject_video: 022_2\n",
      "subject_video: 022_3\n",
      "subject_video: 022_4\n",
      "subject_video: 022_5\n",
      "subject_video: 022_6\n",
      "subject_video: 023_1\n",
      "subject_video: 023_4\n",
      "subject_video: 024_2\n",
      "subject_video: 024_3\n",
      "subject_video: 024_5\n",
      "subject_video: 025_3\n",
      "subject_video: 025_4\n",
      "subject_video: 025_5\n",
      "subject_video: 025_6\n",
      "subject_video: 026_1\n",
      "subject_video: 026_2\n",
      "subject_video: 026_3\n",
      "subject_video: 026_5\n",
      "subject_video: 026_6\n",
      "subject_video: 026_7\n",
      "subject_video: 028_4\n",
      "subject_video: 030_1\n",
      "subject_video: 030_2\n",
      "subject_video: 030_5\n",
      "subject_video: 031_3\n",
      "subject_video: 032_2\n",
      "subject_video: 032_3\n",
      "subject_video: 032_4\n",
      "subject_video: 032_5\n",
      "subject_video: 032_6\n",
      "subject_video: 033_1\n",
      "subject_video: 033_2\n",
      "subject_video: 033_3\n",
      "subject_video: 033_4\n",
      "subject_video: 033_5\n",
      "subject_video: 033_6\n",
      "subject_video: 033_7\n",
      "subject_video: 034_3\n",
      "subject_video: 034_6\n",
      "subject_video: 034_7\n",
      "subject_video: 035_1\n",
      "subject_video: 035_2\n",
      "subject_video: 035_3\n",
      "subject_video: 035_4\n",
      "subject_video: 035_5\n",
      "subject_video: 035_6\n",
      "subject_video: 035_7\n",
      "subject_video: 036_2\n",
      "subject_video: 036_4\n",
      "subject_video: 036_6\n",
      "subject_video: 036_7\n",
      "subject_video: 037_2\n",
      "subject_video: 037_3\n",
      "subject_video: 037_4\n",
      "subject_video: 037_5\n",
      "subject_video: 037_7\n"
     ]
    }
   ],
   "source": [
    "from image_processing import *\n",
    "\n",
    "# videos_images, subjects, subjects_videos_code = load_images(dataset_dir)\n",
    "\n",
    "videos_images, subjects, subjects_videos_code = load_images_dev(\n",
    "    dataset_dir,\n",
    "    images_loading=images_loading,\n",
    "    image_size=image_size,\n",
    "    load_cropped_images=load_cropped_images,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects: ['006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '028', '030', '031', '032', '033', '034', '035', '036', '037']\n",
      "subjects_videos_code: [['1', '2', '3', '4', '5', '6', '7'], ['3', '4', '5', '6', '7'], ['1', '5', '6', '7'], ['2', '3', '4', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '4', '5', '6', '7'], ['1', '2', '3', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '3', '5', '6', '7'], ['1', '2', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '6'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '7'], ['2', '3', '4', '5', '6'], ['1', '4'], ['2', '3', '5'], ['3', '4', '5', '6'], ['1', '2', '3', '5', '6', '7'], ['4'], ['1', '2', '5'], ['3'], ['2', '3', '4', '5', '6'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['2', '4', '6', '7'], ['2', '3', '4', '5', '7']]\n"
     ]
    }
   ],
   "source": [
    "print(\"subjects:\", subjects)\n",
    "print(\"subjects_videos_code:\", subjects_videos_code)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_subject_video_code:  001_2\n",
      "test_subject_video_code:  002_4\n",
      "test_subject_video_code:  003_1\n",
      "test_subject_video_code:  004_3\n",
      "test_subject_video_code:  005_7\n"
     ]
    }
   ],
   "source": [
    "from image_processing import *\n",
    "\n",
    "test_videos_images, test_subjects, test_videos_name = load_images_dev(\n",
    "    test_dataset_dir,\n",
    "    images_loading=images_loading,\n",
    "    image_size=image_size,\n",
    "    load_cropped_images=load_cropped_images,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_subjects: ['001', '002', '003', '004', '005']\n",
      "test_videos_name: ['001_2', '002_4', '003_1', '004_3', '005_7']\n"
     ]
    }
   ],
   "source": [
    "print(\"test_subjects:\", test_subjects)\n",
    "print(\"test_videos_name:\", test_videos_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Excel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Columns: Index(['subject', 'Filename', 'video_code', 'onset', 'apex', 'offset',\n",
      "       'Duration', 'expression_type', 'Action Units', 'Notes',\n",
      "       'subject_video_code', 'subject_code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from label_processing import load_excel\n",
    "\n",
    "Excel_data = load_excel(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>video_code</th>\n",
       "      <th>onset</th>\n",
       "      <th>apex</th>\n",
       "      <th>offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>expression_type</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Notes</th>\n",
       "      <th>subject_video_code</th>\n",
       "      <th>subject_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "      <td>648</td>\n",
       "      <td>743</td>\n",
       "      <td>178</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4(B/C)+7B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_2</td>\n",
       "      <td>1</td>\n",
       "      <td>3562</td>\n",
       "      <td>3588</td>\n",
       "      <td>3632</td>\n",
       "      <td>71</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4+7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>1948</td>\n",
       "      <td>1988</td>\n",
       "      <td>77</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4</td>\n",
       "      <td>While blinking</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_4</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>368</td>\n",
       "      <td>403</td>\n",
       "      <td>80</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4+7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>3343</td>\n",
       "      <td>3388</td>\n",
       "      <td>3424</td>\n",
       "      <td>82</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4+7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject Filename video_code onset  apex offset Duration expression_type  \\\n",
       "0     006  006_1_1          1   566   648    743      178           Macro   \n",
       "1     006  006_1_2          1  3562  3588   3632       71     Micro - 1/2   \n",
       "2     006  006_1_3          1  1912  1948   1988       77     Micro - 1/2   \n",
       "3     006  006_1_4          1   324   368    403       80     Micro - 1/2   \n",
       "4     006  006_1_5          1  3343  3388   3424       82     Micro - 1/2   \n",
       "\n",
       "  Action Units           Notes subject_video_code subject_code  \n",
       "0    4(B/C)+7B             NaN              006_1          006  \n",
       "1          4+7             NaN              006_1          006  \n",
       "2            4  While blinking              006_1          006  \n",
       "3          4+7             NaN              006_1          006  \n",
       "4          4+7             NaN              006_1          006  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_data.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ground Truth Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_videos_index:  [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 95, 97, 98, 99, 100, 101, 103, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146]\n",
      "len(clean_videos_images) = 130\n"
     ]
    }
   ],
   "source": [
    "from label_processing import load_ground_truth_labels\n",
    "\n",
    "\n",
    "(\n",
    "    clean_videos_images,\n",
    "    clean_subjects_videos_code,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    ") = load_ground_truth_labels(\n",
    "    dataset_dir,\n",
    "    expression_type,\n",
    "    videos_images,\n",
    "    subjects_videos_code,\n",
    "    subjects,\n",
    "    Excel_data,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(clean_subjects):  29\n",
      "clean_subjects:  ['006' '007' '008' '009' '010' '011' '012' '013' '014' '015' '016' '017'\n",
      " '018' '019' '020' '021' '022' '023' '024' '025' '026' '028' '030' '032'\n",
      " '033' '034' '035' '036' '037']\n",
      "len(clean_subjects_videos_code):  29\n",
      "clean_subjects_videos_codes:  [['1', '2', '3', '4', '5', '6', '7'], ['5', '6', '7'], ['1', '5', '6', '7'], ['3', '4', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '4', '5', '6', '7'], ['1', '2', '3', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '3', '5', '6', '7'], ['1', '2', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '6'], ['2', '3', '4', '5', '6', '7'], ['1', '2', '3', '5', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['3'], ['2', '3', '6'], ['4'], ['2', '3', '5'], ['3', '5'], ['2', '3', '7'], ['4'], ['1', '2', '5'], ['2', '3', '4', '5', '6'], ['1', '2', '3', '4', '5', '6', '7'], ['6', '7'], ['1', '2', '3', '4', '6', '7'], ['2', '4', '6', '7'], ['2', '3', '4', '5', '7']]\n",
      "len(clean_subjects_videos_ground_truth_labels):  29\n",
      "clean_subjects_videos_ground_truth_labels[6]:  [[[5029, 5474]], [[1340, 1524]], [[616, 800]], [[2887, 3066], [4083, 4279], [4342, 4514], [238, 353]], [[951, 1180]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"len(clean_subjects): \", len(clean_subjects))\n",
    "print(\"clean_subjects: \", clean_subjects)\n",
    "print(\"len(clean_subjects_videos_code): \", len(clean_subjects_videos_code))\n",
    "print(\"clean_subjects_videos_codes: \", clean_subjects_videos_code)\n",
    "print(\n",
    "    \"len(clean_subjects_videos_ground_truth_labels): \",\n",
    "    len(clean_subjects_videos_ground_truth_labels),\n",
    ")\n",
    "\n",
    "# 7 (s23) has happy1 (0502) in excel but the folder name is happy2 (0503)\n",
    "print(\n",
    "    \"clean_subjects_videos_ground_truth_labels[6]: \",\n",
    "    clean_subjects_videos_ground_truth_labels[6],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 006: ['1', '2', '3', '4', '5', '6', '7'], ground truth len: 23\n",
      "1 007: ['5', '6', '7'], ground truth len: 5\n",
      "2 008: ['1', '5', '6', '7'], ground truth len: 5\n",
      "3 009: ['3', '4', '6', '7'], ground truth len: 6\n",
      "4 010: ['1', '2', '3', '4', '5', '6', '7'], ground truth len: 19\n",
      "5 011: ['1', '2', '3', '4', '5', '6', '7'], ground truth len: 46\n",
      "6 012: ['3', '4', '5', '6', '7'], ground truth len: 8\n",
      "7 013: ['1', '2', '3', '6', '7'], ground truth len: 14\n",
      "8 014: ['1', '2', '3', '4', '5', '6', '7'], ground truth len: 20\n",
      "9 015: ['1', '3', '5', '6', '7'], ground truth len: 15\n",
      "10 016: ['1', '2', '4', '5', '6', '7'], ground truth len: 11\n",
      "11 017: ['1', '2', '3', '4', '5', '6'], ground truth len: 6\n",
      "12 018: ['2', '3', '4', '5', '6', '7'], ground truth len: 16\n",
      "13 019: ['1', '2', '3', '5', '7'], ground truth len: 14\n",
      "14 020: ['1', '2', '3', '4', '5', '6', '7'], ground truth len: 22\n",
      "15 021: ['3'], ground truth len: 2\n",
      "16 022: ['2', '3', '6'], ground truth len: 7\n",
      "17 023: ['4'], ground truth len: 1\n",
      "18 024: ['2', '3', '5'], ground truth len: 7\n",
      "19 025: ['3', '5'], ground truth len: 5\n",
      "20 026: ['2', '3', '7'], ground truth len: 8\n",
      "21 028: ['4'], ground truth len: 2\n",
      "22 030: ['1', '2', '5'], ground truth len: 5\n",
      "23 032: ['2', '3', '4', '5', '6'], ground truth len: 10\n",
      "24 033: ['1', '2', '3', '4', '5', '6', '7'], ground truth len: 11\n",
      "25 034: ['6', '7'], ground truth len: 4\n",
      "26 035: ['1', '2', '3', '4', '6', '7'], ground truth len: 13\n",
      "27 036: ['2', '4', '6', '7'], ground truth len: 17\n",
      "28 037: ['2', '3', '4', '5', '7'], ground truth len: 9\n",
      "total len:  331\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "for index, clean_subject_videos_code in enumerate(clean_subjects_videos_code):\n",
    "    ground_truth_len = 0\n",
    "    for i in clean_subjects_videos_ground_truth_labels[index]:\n",
    "        for j in i:\n",
    "            ground_truth_len += 1\n",
    "    print(\n",
    "        f\"{index} {clean_subjects[index]}: {clean_subject_videos_code}, ground truth len: {ground_truth_len}\"\n",
    "    )\n",
    "    total_len += ground_truth_len\n",
    "print(\"total len: \", total_len)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k (Half of average length of expression) =  169\n"
     ]
    }
   ],
   "source": [
    "from label_processing import calculate_k\n",
    "\n",
    "k = calculate_k(clean_subjects_videos_ground_truth_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features and Pro-process\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about ? m.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features_extraction_and_pre_processing import *\n",
    "\n",
    "# extract_features_and_pre_process_test(\n",
    "#     clean_videos_images=test_videos_images,\n",
    "#     k=k,\n",
    "#     expression_type=expression_type,\n",
    "#     test_dataset_dir=test_dataset_dir,\n",
    "#     image_size=image_size,\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 1493 m.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Optical Flow Features (shape = [128, 128, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features_extraction import extract_features\n",
    "\n",
    "# clean_videos_images_features = extract_features(clean_videos_images, k, image_size=128)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 384 m.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processing import pre_process\n",
    "\n",
    "# resampled_clean_videos_images_features = preprocess(\n",
    "#     clean_videos_images, clean_videos_images_features, k\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump Resampled Clean Videos Images Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if expression_type == \"micro-expression\":\n",
    "#     with open(\n",
    "#         Path(\n",
    "#             dataset_dir,\n",
    "#             \"resampled_clean_videos_images_me_features_\" + str(image_size) + \".pkl\",\n",
    "#         ),\n",
    "#         \"wb\",\n",
    "#     ) as pkl_file:\n",
    "#         _pickle.dump(resampled_clean_videos_images_features, pkl_file)\n",
    "#         pkl_file.close()\n",
    "# elif expression_type == \"macro-expression\":\n",
    "#     with open(\n",
    "#         Path(\n",
    "#             dataset_dir,\n",
    "#             \"resampled_clean_videos_images_mae_features_\" + str(image_size) + \".pkl\",\n",
    "#         ),\n",
    "#         \"wb\",\n",
    "#     ) as pkl_file:\n",
    "#         _pickle.dump(resampled_clean_videos_images_features, pkl_file)\n",
    "#         pkl_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load **Original** Resampled Clean Videos Images Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if expression_type == \"micro-expression\":\n",
    "#     with open(\n",
    "#         Path(\n",
    "#             dataset_dir,\n",
    "#             \"original_resampled_clean_videos_images_me_features.pkl\",\n",
    "#         ),\n",
    "#         \"rb\",\n",
    "#     ) as pkl_file:\n",
    "#         resampled_clean_videos_images_features = _pickle.load(pkl_file)\n",
    "#         pkl_file.close()\n",
    "# elif expression_type == \"macro-expression\":\n",
    "#     with open(\n",
    "#         Path(\n",
    "#             dataset_dir,\n",
    "#             \"original_resampled_clean_videos_images_mae_features.pkl\",\n",
    "#         ),\n",
    "#         \"rb\",\n",
    "#     ) as pkl_file:\n",
    "#         resampled_clean_videos_images_features = _pickle.load(pkl_file)\n",
    "#         pkl_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Resampled Clean Videos Images Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_x is True and debug_preds is False:\n",
    "    if expression_type == \"micro-expression\":\n",
    "        with open(\n",
    "            Path(\n",
    "                dataset_dir,\n",
    "                \"resampled_clean_videos_images_me_features_\" + str(image_size) + \".pkl\",\n",
    "            ),\n",
    "            \"rb\",\n",
    "        ) as pkl_file:\n",
    "            resampled_clean_videos_images_features = _pickle.load(pkl_file)\n",
    "            pkl_file.close()\n",
    "    elif expression_type == \"macro-expression\":\n",
    "        with open(\n",
    "            Path(\n",
    "                dataset_dir,\n",
    "                \"resampled_clean_videos_images_mae_features_\"\n",
    "                + str(image_size)\n",
    "                + \".pkl\",\n",
    "            ),\n",
    "            \"rb\",\n",
    "        ) as pkl_file:\n",
    "            resampled_clean_videos_images_features = _pickle.load(pkl_file)\n",
    "            pkl_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_x is True and debug_preds is False:\n",
    "    print(\n",
    "        \"len(resampled_clean_videos_images_features): \",\n",
    "        len(resampled_clean_videos_images_features),\n",
    "    )\n",
    "    print(\n",
    "        \"len(resampled_clean_videos_images_features[0]): \",\n",
    "        len(resampled_clean_videos_images_features[0]),\n",
    "    )\n",
    "    print(\n",
    "        \"resampled_clean_videos_images_features[0][0].shape: \",\n",
    "        resampled_clean_videos_images_features[0][0].shape,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 438311\n"
     ]
    }
   ],
   "source": [
    "from labeling import *\n",
    "\n",
    "labels = pseudo_labeling(\n",
    "    clean_videos_images, clean_subjects_videos_ground_truth_labels, k\n",
    ")\n",
    "\n",
    "# labels = original_labeling(\n",
    "#     clean_videos_images, clean_subjects_videos_ground_truth_labels, k\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from training_test_dev import train_and_test\n",
    "\n",
    "model_names = {\n",
    "    0: \"SOFTNet\",\n",
    "    1: \"SOFTNetCBAM\",\n",
    "    2: \"ViT\",\n",
    "    3: \"SL-ViT\",\n",
    "    4: \"Swin-T\",\n",
    "    5: \"Swin-S\",\n",
    "    6: \"SL-Swin-T\",\n",
    "    7: \"SL-Swin-S\",\n",
    "}\n",
    "\n",
    "\n",
    "if debug_preds is False:\n",
    "    preds = train_and_test(\n",
    "        dataset_dir,\n",
    "        test_dataset_dir,\n",
    "        clean_subjects,\n",
    "        test_videos_name,\n",
    "        y=labels,\n",
    "        expression_type=expression_type,\n",
    "        model_name=model_names[6],\n",
    "        train_or_not=True,\n",
    "        epochs=25,\n",
    "        batch_size=32,\n",
    "    )\n",
    "else:\n",
    "    with open(\n",
    "        Path(\n",
    "            dataset_dir,\n",
    "            \"preds\",\n",
    "            \"mae_sl_swin_s_epochs_25_batch_size_48_128.pkl\",\n",
    "        ),\n",
    "        \"rb\",\n",
    "    ) as pkl_file:\n",
    "        preds = _pickle.load(pkl_file)\n",
    "        pkl_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotting\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "macro expression works better when `distance = k` .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotting import *\n",
    "\n",
    "test_videos_preds = spot_test(\n",
    "    preds=preds, k=k, p=0.55, test_videos_name=test_videos_name, show_plot_or_not=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print for csv submission\n",
    "print(\"vid,pred_onset,pred_offset,type\")\n",
    "type = \"me\" if expression_type == \"micro-expression\" else \"mae\"\n",
    "for test_video_name, test_video_preds in zip(test_videos_name, test_videos_preds):\n",
    "    if len(test_video_preds) != 0:\n",
    "        for test_video_pred in test_video_preds:\n",
    "            print(f\"{test_video_name},{test_video_pred[0]},{test_video_pred[1]},{type}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6696e3028ae55fa5be357812587f73779dfb157cc851dab91c4ca8ffd3c7a806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
