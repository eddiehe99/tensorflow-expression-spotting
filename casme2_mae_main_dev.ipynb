{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `autoreload` to execute the change in `.py` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from __utils__ import images_processing\n",
    "from __utils__ import labels_processing\n",
    "from __utils__ import labeling\n",
    "from __utils__ import loso_preparing\n",
    "from __utils__ import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"D:/Databases/CAS(ME)^2\"\n",
    "# dataset_dir = \"I:/HEH/Databases/CAS(ME)^2\"\n",
    "# dataset_dir = \"/data/disk1/heh/databases/CAS(ME)^2\"\n",
    "\n",
    "images_loading = False\n",
    "image_size = 128\n",
    "load_cropped_images = False\n",
    "expression_type = \"mae\"  # macro-expression spotting\n",
    "# expression_type = \"me\"  # micro-expression spotting\n",
    "debug_preds = True\n",
    "labeling_function = \"pseudo_labeling\"\n",
    "# labeling_function = \"original_labeling\"\n",
    "model_names = {\n",
    "    0: \"SOFTNet\",\n",
    "    1: \"SOFTNetCBAM\",\n",
    "    2: \"ViT-B\",\n",
    "    3: \"SL-ViT-B\",\n",
    "    4: \"Swin-T\",\n",
    "    5: \"Swin-S\",\n",
    "    6: \"L-Swin-T\",\n",
    "    7: \"S-Swin-T\",\n",
    "    8: \"SL-Swin-T\",\n",
    "    9: \"SL-Swin-S\",\n",
    "}\n",
    "model_name = model_names[8]\n",
    "batch_size = 48\n",
    "epochs = 25\n",
    "save_preds = False\n",
    "preds_stem = (\n",
    "    f\"{expression_type}_\"\n",
    "    + model_name.lower().replace(\"-\", \"_\")\n",
    "    + f\"_batch_size_{batch_size}\"\n",
    "    + f\"_epochs_{epochs}\"\n",
    "    + f\"_{labeling_function}\"\n",
    "    + f\"_{image_size}\"\n",
    "    + \"_3\"\n",
    ")\n",
    "preds_path = Path(dataset_dir, \"preds\", preds_stem).with_suffix(\".pkl\")\n",
    "print(f\"preds_path: {preds_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When debug the image processing, the videos_images is from cropped_rawpic, whereas the other variables are from rawpic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  s15\n",
      "subject:  s16\n",
      "subject:  s19\n",
      "subject:  s20\n",
      "subject:  s21\n",
      "subject:  s22\n",
      "subject:  s23\n",
      "subject:  s24\n",
      "subject:  s25\n",
      "subject:  s26\n",
      "subject:  s27\n",
      "subject:  s29\n",
      "subject:  s30\n",
      "subject:  s31\n",
      "subject:  s32\n",
      "subject:  s33\n",
      "subject:  s34\n",
      "subject:  s35\n",
      "subject:  s36\n",
      "subject:  s37\n",
      "subject:  s38\n",
      "subject:  s40\n"
     ]
    }
   ],
   "source": [
    "videos_images, subjects, subjects_videos_code = images_processing.load_images_dev(\n",
    "    dataset_dir,\n",
    "    images_loading=images_loading,\n",
    "    image_size=image_size,\n",
    "    load_cropped_images=load_cropped_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects: ['s15', 's16', 's19', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's29', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's40']\n",
      "subjects_videos_code: [['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0508'], ['0101', '0102', '0401', '0402', '0502', '0505', '0507'], ['0102', '0402', '0505', '0507', '0502'], ['0502'], ['0101', '0401'], ['0101', '0102', '0402', '0503', '0508'], ['0102', '0402', '0503', '0507'], ['0101', '0401', '0402', '0502', '0507'], ['0101', '0102', '0502', '0508'], ['0101', '0102', '0401', '0503'], ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507', '0508'], ['0502'], ['0101', '0102', '0401', '0502', '0503', '0505', '0507'], ['0101', '0401', '0402', '0502', '0503', '0505', '0507'], ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507', '0508'], ['0102', '0402'], ['0401', '0402', '0503'], ['0102'], ['0401', '0505'], ['0101', '0402', '0502', '0505', '0507', '0508'], ['0502', '0507'], ['0401', '0502', '0503']]\n"
     ]
    }
   ],
   "source": [
    "print(\"subjects:\", subjects)\n",
    "print(\"subjects_videos_code:\", subjects_videos_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Excel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>video_name_&amp;_expression_number</th>\n",
       "      <th>onset</th>\n",
       "      <th>apex</th>\n",
       "      <th>offset</th>\n",
       "      <th>AUs</th>\n",
       "      <th>extimated_emotion</th>\n",
       "      <th>expression_type</th>\n",
       "      <th>self-reported_emotion</th>\n",
       "      <th>video_name</th>\n",
       "      <th>video_code</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anger1_1</td>\n",
       "      <td>557</td>\n",
       "      <td>572</td>\n",
       "      <td>608</td>\n",
       "      <td>4+10+14+15</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger1</td>\n",
       "      <td>0401</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anger1_2</td>\n",
       "      <td>2854</td>\n",
       "      <td>2862</td>\n",
       "      <td>2871</td>\n",
       "      <td>38</td>\n",
       "      <td>others</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>sadness</td>\n",
       "      <td>anger1</td>\n",
       "      <td>0401</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>anger2_1</td>\n",
       "      <td>2155</td>\n",
       "      <td>2163</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger2</td>\n",
       "      <td>0402</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>anger2_2</td>\n",
       "      <td>3363</td>\n",
       "      <td>3371</td>\n",
       "      <td>3383</td>\n",
       "      <td>4+7+14</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger2</td>\n",
       "      <td>0402</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>anger2_3</td>\n",
       "      <td>3380</td>\n",
       "      <td>3386</td>\n",
       "      <td>3407</td>\n",
       "      <td>4+14+38</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger2</td>\n",
       "      <td>0402</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant video_name_&_expression_number  onset  apex  offset  \\\n",
       "0            1                       anger1_1    557   572     608   \n",
       "1            1                       anger1_2   2854  2862    2871   \n",
       "2            1                       anger2_1   2155  2163       0   \n",
       "3            1                       anger2_2   3363  3371    3383   \n",
       "4            1                       anger2_3   3380  3386    3407   \n",
       "\n",
       "          AUs extimated_emotion   expression_type self-reported_emotion  \\\n",
       "0  4+10+14+15          negative  macro-expression                 anger   \n",
       "1          38            others  macro-expression               sadness   \n",
       "2         NaN          negative  macro-expression                 anger   \n",
       "3      4+7+14          negative  macro-expression                 anger   \n",
       "4     4+14+38          negative  macro-expression                 anger   \n",
       "\n",
       "  video_name video_code subject  \n",
       "0     anger1       0401     s15  \n",
       "1     anger1       0401     s15  \n",
       "2     anger2       0402     s15  \n",
       "3     anger2       0402     s15  \n",
       "4     anger2       0402     s15  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_data = labels_processing.load_excel(dataset_dir)\n",
    "Excel_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ground Truth Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_videos_index:  [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96]\n",
      "len(clean_videos_images) = 88\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    clean_videos_images,\n",
    "    clean_subjects_videos_code,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    ") = labels_processing.load_ground_truth_labels(\n",
    "    dataset_dir,\n",
    "    expression_type,\n",
    "    videos_images,\n",
    "    subjects_videos_code,\n",
    "    subjects,\n",
    "    Excel_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(clean_subjects):  20\n",
      "clean_subjects:  ['s15' 's16' 's19' 's20' 's21' 's22' 's23' 's24' 's25' 's26' 's27' 's30'\n",
      " 's31' 's32' 's33' 's34' 's36' 's37' 's38' 's40']\n",
      "len(clean_subjects_videos_code):  20\n",
      "clean_subjects_videos_codes:  [['0101', '0102', '0401', '0402', '0502', '0503', '0505'], ['0101', '0102', '0401', '0402', '0502', '0505', '0507'], ['0102', '0505', '0507'], ['0502'], ['0101', '0401'], ['0101', '0102', '0402', '0503', '0508'], ['0102', '0402', '0507'], ['0101', '0401', '0402', '0502', '0507'], ['0102', '0502', '0508'], ['0101', '0102', '0401', '0503'], ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507', '0508'], ['0102', '0401', '0502', '0503', '0505', '0507'], ['0101', '0401', '0402', '0502', '0503', '0505', '0507'], ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507'], ['0102', '0402'], ['0401', '0402', '0503'], ['0401', '0505'], ['0101', '0402', '0502', '0505', '0507', '0508'], ['0502', '0507'], ['0401', '0502', '0503']]\n",
      "len(clean_subjects_videos_ground_truth_labels):  20\n",
      "clean_subjects_videos_ground_truth_labels[6]:  [[[912, 939], [996, 1014]], [[3684, 3718], [3798, 3817], [3878, 3902]], [[2743, 2763]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"len(clean_subjects): \", len(clean_subjects))\n",
    "print(\"clean_subjects: \", clean_subjects)\n",
    "print(\"len(clean_subjects_videos_code): \", len(clean_subjects_videos_code))\n",
    "print(\"clean_subjects_videos_codes: \", clean_subjects_videos_code)\n",
    "print(\n",
    "    \"len(clean_subjects_videos_ground_truth_labels): \",\n",
    "    len(clean_subjects_videos_ground_truth_labels),\n",
    ")\n",
    "\n",
    "# 7 (s23) has happy1 (0502) in excel but the folder name is happy2 (0503)\n",
    "print(\n",
    "    \"clean_subjects_videos_ground_truth_labels[6]: \",\n",
    "    clean_subjects_videos_ground_truth_labels[6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 s15: ['0101', '0102', '0401', '0402', '0502', '0503', '0505'], ground truth len: 15\n",
      "1 s16: ['0101', '0102', '0401', '0402', '0502', '0505', '0507'], ground truth len: 46\n",
      "2 s19: ['0102', '0505', '0507'], ground truth len: 4\n",
      "3 s20: ['0502'], ground truth len: 3\n",
      "4 s21: ['0101', '0401'], ground truth len: 2\n",
      "5 s22: ['0101', '0102', '0402', '0503', '0508'], ground truth len: 16\n",
      "6 s23: ['0102', '0402', '0507'], ground truth len: 6\n",
      "7 s24: ['0101', '0401', '0402', '0502', '0507'], ground truth len: 24\n",
      "8 s25: ['0102', '0502', '0508'], ground truth len: 5\n",
      "9 s26: ['0101', '0102', '0401', '0503'], ground truth len: 6\n",
      "10 s27: ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507', '0508'], ground truth len: 32\n",
      "11 s30: ['0102', '0401', '0502', '0503', '0505', '0507'], ground truth len: 17\n",
      "12 s31: ['0101', '0401', '0402', '0502', '0503', '0505', '0507'], ground truth len: 26\n",
      "13 s32: ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507'], ground truth len: 48\n",
      "14 s33: ['0102', '0402'], ground truth len: 4\n",
      "15 s34: ['0401', '0402', '0503'], ground truth len: 3\n",
      "16 s36: ['0401', '0505'], ground truth len: 4\n",
      "17 s37: ['0101', '0402', '0502', '0505', '0507', '0508'], ground truth len: 21\n",
      "18 s38: ['0502', '0507'], ground truth len: 11\n",
      "19 s40: ['0401', '0502', '0503'], ground truth len: 5\n",
      "total len:  298\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "for index, clean_subject_videos_code in enumerate(clean_subjects_videos_code):\n",
    "    ground_truth_len = 0\n",
    "    for i in clean_subjects_videos_ground_truth_labels[index]:\n",
    "        for j in i:\n",
    "            ground_truth_len += 1\n",
    "    print(\n",
    "        f\"{index} {clean_subjects[index]}: {clean_subject_videos_code}, ground truth len: {ground_truth_len}\"\n",
    "    )\n",
    "    total_len += ground_truth_len\n",
    "print(\"total len: \", total_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k (Half of average length of expression) =  18\n"
     ]
    }
   ],
   "source": [
    "k = labels_processing.calculate_k(clean_subjects_videos_ground_truth_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 231999\n"
     ]
    }
   ],
   "source": [
    "if debug_preds is False:\n",
    "    if labeling_function == \"pseudo_labeling\":\n",
    "        labels = labeling.get_pseudo_labels(\n",
    "            clean_videos_images, clean_subjects_videos_ground_truth_labels, k\n",
    "        )\n",
    "    elif labeling_function == \"original_labeling\":\n",
    "        labels = labeling.get_original_labels(\n",
    "            clean_videos_images, clean_subjects_videos_ground_truth_labels, k\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for LOSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Index for each subject:-\n",
      "\n",
      "subject s15 ( group = 0): 0 -> 18470\n",
      "subject s15 has 7 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  7\n",
      "\n",
      "subject s16 ( group = 1): 18470 -> 37392\n",
      "subject s16 has 7 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  14\n",
      "\n",
      "subject s19 ( group = 2): 37392 -> 43977\n",
      "subject s19 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  17\n",
      "\n",
      "subject s20 ( group = 3): 43977 -> 46233\n",
      "subject s20 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  18\n",
      "\n",
      "subject s21 ( group = 4): 46233 -> 51966\n",
      "subject s21 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  20\n",
      "\n",
      "subject s22 ( group = 5): 51966 -> 62840\n",
      "subject s22 has 5 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  25\n",
      "\n",
      "subject s23 ( group = 6): 62840 -> 71496\n",
      "subject s23 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  28\n",
      "\n",
      "subject s24 ( group = 7): 71496 -> 87084\n",
      "subject s24 has 5 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  33\n",
      "\n",
      "subject s25 ( group = 8): 87084 -> 91039\n",
      "subject s25 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  36\n",
      "\n",
      "subject s26 ( group = 9): 91039 -> 100614\n",
      "subject s26 has 4 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  40\n",
      "\n",
      "subject s27 ( group = 10): 100614 -> 122975\n",
      "subject s27 has 9 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  49\n",
      "\n",
      "subject s30 ( group = 11): 122975 -> 138303\n",
      "subject s30 has 6 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  55\n",
      "\n",
      "subject s31 ( group = 12): 138303 -> 158962\n",
      "subject s31 has 7 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  62\n",
      "\n",
      "subject s32 ( group = 13): 158962 -> 180687\n",
      "subject s32 has 8 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  70\n",
      "\n",
      "subject s33 ( group = 14): 180687 -> 186097\n",
      "subject s33 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  72\n",
      "\n",
      "subject s34 ( group = 15): 186097 -> 196940\n",
      "subject s34 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  75\n",
      "\n",
      "subject s36 ( group = 16): 196940 -> 202930\n",
      "subject s36 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  77\n",
      "\n",
      "subject s37 ( group = 17): 202930 -> 217745\n",
      "subject s37 has 6 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  83\n",
      "\n",
      "subject s38 ( group = 18): 217745 -> 223250\n",
      "subject s38 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  85\n",
      "\n",
      "subject s40 ( group = 19): 223250 -> 231999\n",
      "subject s40 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  88\n"
     ]
    }
   ],
   "source": [
    "y, groups = loso_preparing.prepare_for_loso(\n",
    "    labels,\n",
    "    clean_subjects,\n",
    "    clean_videos_images,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    "    k,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_preds is False:\n",
    "    from __utils__.training_dev import train\n",
    "\n",
    "    preds = train(\n",
    "        dataset_dir,\n",
    "        clean_subjects,\n",
    "        y=y,\n",
    "        expression_type=expression_type,\n",
    "        model_name=model_name,\n",
    "        train_or_not=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "else:\n",
    "    with open(preds_path, \"rb\") as pkl_file:\n",
    "        preds = _pickle.load(pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_preds is True:\n",
    "    with open(preds_path, \"wb\") as pkl_file:\n",
    "        _pickle.dump(preds, pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotting and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 / 20 is in process.\n",
      "0 video(s) have been processed.\n",
      "The current video be processed: subject s15, video 0101\n",
      "The current video be processed: subject s15, video 0102\n",
      "The current video be processed: subject s15, video 0401\n",
      "The current video be processed: subject s15, video 0402\n",
      "The current video be processed: subject s15, video 0502\n",
      "The current video be processed: subject s15, video 0503\n",
      "The current video be processed: subject s15, video 0505\n",
      "\n",
      "True Positive: 3 False Posive: 22 False Negative: 12\n",
      "Precision = 0.12000000000000022, Recall =0.20000000000000023, F1-Score = 0.15000000000000044\n",
      "Split 0 / 20 is processed.\n",
      "\n",
      "Split 1 / 20 is in process.\n",
      "7 video(s) have been processed.\n",
      "The current video be processed: subject s16, video 0101\n",
      "The current video be processed: subject s16, video 0102\n",
      "The current video be processed: subject s16, video 0401\n",
      "The current video be processed: subject s16, video 0402\n",
      "The current video be processed: subject s16, video 0502\n",
      "The current video be processed: subject s16, video 0505\n",
      "The current video be processed: subject s16, video 0507\n",
      "\n",
      "True Positive: 9 False Posive: 43 False Negative: 52\n",
      "Precision = 0.1730769230769233, Recall =0.1475409836065576, F1-Score = 0.15929203539823053\n",
      "Split 1 / 20 is processed.\n",
      "\n",
      "Split 2 / 20 is in process.\n",
      "14 video(s) have been processed.\n",
      "The current video be processed: subject s19, video 0102\n",
      "The current video be processed: subject s19, video 0505\n",
      "The current video be processed: subject s19, video 0507\n",
      "\n",
      "True Positive: 12 False Posive: 49 False Negative: 53\n",
      "Precision = 0.19672131147541005, Recall =0.18461538461538485, F1-Score = 0.1904761904761909\n",
      "Split 2 / 20 is processed.\n",
      "\n",
      "Split 3 / 20 is in process.\n",
      "17 video(s) have been processed.\n",
      "The current video be processed: subject s20, video 0502\n",
      "\n",
      "True Positive: 12 False Posive: 52 False Negative: 56\n",
      "Precision = 0.18750000000000022, Recall =0.17647058823529435, F1-Score = 0.18181818181818227\n",
      "Split 3 / 20 is processed.\n",
      "\n",
      "Split 4 / 20 is in process.\n",
      "18 video(s) have been processed.\n",
      "The current video be processed: subject s21, video 0101\n",
      "The current video be processed: subject s21, video 0401\n",
      "\n",
      "True Positive: 12 False Posive: 63 False Negative: 58\n",
      "Precision = 0.16000000000000023, Recall =0.17142857142857165, F1-Score = 0.16551724137931081\n",
      "Split 4 / 20 is processed.\n",
      "\n",
      "Split 5 / 20 is in process.\n",
      "20 video(s) have been processed.\n",
      "The current video be processed: subject s22, video 0101\n",
      "The current video be processed: subject s22, video 0102\n",
      "The current video be processed: subject s22, video 0402\n",
      "The current video be processed: subject s22, video 0503\n",
      "The current video be processed: subject s22, video 0508\n",
      "\n",
      "True Positive: 15 False Posive: 71 False Negative: 71\n",
      "Precision = 0.17441860465116302, Recall =0.17441860465116302, F1-Score = 0.17441860465116324\n",
      "Split 5 / 20 is processed.\n",
      "\n",
      "Split 6 / 20 is in process.\n",
      "25 video(s) have been processed.\n",
      "The current video be processed: subject s23, video 0102\n",
      "The current video be processed: subject s23, video 0402\n",
      "The current video be processed: subject s23, video 0507\n",
      "\n",
      "True Positive: 15 False Posive: 97 False Negative: 77\n",
      "Precision = 0.13392857142857165, Recall =0.1630434782608698, F1-Score = 0.1470588235294122\n",
      "Split 6 / 20 is processed.\n",
      "\n",
      "Split 7 / 20 is in process.\n",
      "28 video(s) have been processed.\n",
      "The current video be processed: subject s24, video 0101\n",
      "The current video be processed: subject s24, video 0401\n",
      "The current video be processed: subject s24, video 0402\n",
      "The current video be processed: subject s24, video 0502\n",
      "The current video be processed: subject s24, video 0507\n",
      "\n",
      "True Positive: 22 False Posive: 115 False Negative: 94\n",
      "Precision = 0.16058394160583964, Recall =0.18965517241379332, F1-Score = 0.17391304347826134\n",
      "Split 7 / 20 is processed.\n",
      "\n",
      "Split 8 / 20 is in process.\n",
      "33 video(s) have been processed.\n",
      "The current video be processed: subject s25, video 0102\n",
      "The current video be processed: subject s25, video 0502\n",
      "The current video be processed: subject s25, video 0508\n",
      "\n",
      "True Positive: 24 False Posive: 129 False Negative: 97\n",
      "Precision = 0.15686274509803944, Recall =0.19834710743801676, F1-Score = 0.17518248175182527\n",
      "Split 8 / 20 is processed.\n",
      "\n",
      "Split 9 / 20 is in process.\n",
      "36 video(s) have been processed.\n",
      "The current video be processed: subject s26, video 0101\n",
      "The current video be processed: subject s26, video 0102\n",
      "The current video be processed: subject s26, video 0401\n",
      "The current video be processed: subject s26, video 0503\n",
      "\n",
      "True Positive: 25 False Posive: 135 False Negative: 102\n",
      "Precision = 0.15625000000000022, Recall =0.19685039370078763, F1-Score = 0.17421602787456492\n",
      "Split 9 / 20 is processed.\n",
      "\n",
      "Split 10 / 20 is in process.\n",
      "40 video(s) have been processed.\n",
      "The current video be processed: subject s27, video 0101\n",
      "The current video be processed: subject s27, video 0102\n",
      "The current video be processed: subject s27, video 0401\n",
      "The current video be processed: subject s27, video 0402\n",
      "The current video be processed: subject s27, video 0502\n",
      "The current video be processed: subject s27, video 0503\n",
      "The current video be processed: subject s27, video 0505\n",
      "The current video be processed: subject s27, video 0507\n",
      "The current video be processed: subject s27, video 0508\n",
      "\n",
      "True Positive: 38 False Posive: 161 False Negative: 121\n",
      "Precision = 0.19095477386934695, Recall =0.23899371069182412, F1-Score = 0.21229050279329653\n",
      "Split 10 / 20 is processed.\n",
      "\n",
      "Split 11 / 20 is in process.\n",
      "49 video(s) have been processed.\n",
      "The current video be processed: subject s30, video 0102\n",
      "The current video be processed: subject s30, video 0401\n",
      "The current video be processed: subject s30, video 0502\n",
      "The current video be processed: subject s30, video 0503\n",
      "The current video be processed: subject s30, video 0505\n",
      "The current video be processed: subject s30, video 0507\n",
      "\n",
      "True Positive: 42 False Posive: 176 False Negative: 134\n",
      "Precision = 0.19266055045871583, Recall =0.23863636363636387, F1-Score = 0.21319796954314768\n",
      "Split 11 / 20 is processed.\n",
      "\n",
      "Split 12 / 20 is in process.\n",
      "55 video(s) have been processed.\n",
      "The current video be processed: subject s31, video 0101\n",
      "The current video be processed: subject s31, video 0401\n",
      "The current video be processed: subject s31, video 0402\n",
      "The current video be processed: subject s31, video 0502\n",
      "The current video be processed: subject s31, video 0503\n",
      "The current video be processed: subject s31, video 0505\n",
      "The current video be processed: subject s31, video 0507\n",
      "\n",
      "True Positive: 49 False Posive: 202 False Negative: 153\n",
      "Precision = 0.1952191235059763, Recall =0.2425742574257428, F1-Score = 0.21633554083885256\n",
      "Split 12 / 20 is processed.\n",
      "\n",
      "Split 13 / 20 is in process.\n",
      "62 video(s) have been processed.\n",
      "The current video be processed: subject s32, video 0101\n",
      "The current video be processed: subject s32, video 0102\n",
      "The current video be processed: subject s32, video 0401\n",
      "The current video be processed: subject s32, video 0402\n",
      "The current video be processed: subject s32, video 0502\n",
      "The current video be processed: subject s32, video 0503\n",
      "The current video be processed: subject s32, video 0505\n",
      "The current video be processed: subject s32, video 0507\n",
      "\n",
      "True Positive: 63 False Posive: 224 False Negative: 187\n",
      "Precision = 0.21951219512195144, Recall =0.2520000000000002, F1-Score = 0.23463687150838033\n",
      "Split 13 / 20 is processed.\n",
      "\n",
      "Split 14 / 20 is in process.\n",
      "70 video(s) have been processed.\n",
      "The current video be processed: subject s33, video 0102\n",
      "The current video be processed: subject s33, video 0402\n",
      "\n",
      "True Positive: 63 False Posive: 234 False Negative: 191\n",
      "Precision = 0.21212121212121235, Recall =0.24803149606299235, F1-Score = 0.2286751361161529\n",
      "Split 14 / 20 is processed.\n",
      "\n",
      "Split 15 / 20 is in process.\n",
      "72 video(s) have been processed.\n",
      "The current video be processed: subject s34, video 0401\n",
      "The current video be processed: subject s34, video 0402\n",
      "The current video be processed: subject s34, video 0503\n",
      "\n",
      "True Positive: 63 False Posive: 257 False Negative: 194\n",
      "Precision = 0.19687500000000022, Recall =0.24513618677042823, F1-Score = 0.21837088388214948\n",
      "Split 15 / 20 is processed.\n",
      "\n",
      "Split 16 / 20 is in process.\n",
      "75 video(s) have been processed.\n",
      "The current video be processed: subject s36, video 0401\n",
      "The current video be processed: subject s36, video 0505\n",
      "\n",
      "True Positive: 64 False Posive: 265 False Negative: 197\n",
      "Precision = 0.19452887537993943, Recall =0.24521072796934887, F1-Score = 0.21694915254237332\n",
      "Split 16 / 20 is processed.\n",
      "\n",
      "Split 17 / 20 is in process.\n",
      "77 video(s) have been processed.\n",
      "The current video be processed: subject s37, video 0101\n",
      "The current video be processed: subject s37, video 0402\n",
      "The current video be processed: subject s37, video 0502\n",
      "The current video be processed: subject s37, video 0505\n",
      "The current video be processed: subject s37, video 0507\n",
      "The current video be processed: subject s37, video 0508\n",
      "\n",
      "True Positive: 65 False Posive: 282 False Negative: 217\n",
      "Precision = 0.18731988472622502, Recall =0.23049645390070944, F1-Score = 0.20667726550079535\n",
      "Split 17 / 20 is processed.\n",
      "\n",
      "Split 18 / 20 is in process.\n",
      "83 video(s) have been processed.\n",
      "The current video be processed: subject s38, video 0502\n",
      "The current video be processed: subject s38, video 0507\n",
      "\n",
      "True Positive: 68 False Posive: 288 False Negative: 225\n",
      "Precision = 0.1910112359550564, Recall =0.23208191126279887, F1-Score = 0.2095531587057015\n",
      "Split 18 / 20 is processed.\n",
      "\n",
      "Split 19 / 20 is in process.\n",
      "85 video(s) have been processed.\n",
      "The current video be processed: subject s40, video 0401\n",
      "The current video be processed: subject s40, video 0502\n",
      "The current video be processed: subject s40, video 0503\n",
      "\n",
      "True Positive: 68 False Posive: 297 False Negative: 230\n",
      "Precision = 0.18630136986301393, Recall =0.22818791946308747, F1-Score = 0.2051282051282056\n",
      "Split 19 / 20 is processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_fn, result_dict = functions.spot_and_evaluate(\n",
    "    preds,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    "    clean_videos_images,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_code,\n",
    "    k,\n",
    "    p=0.60,\n",
    "    show_plot_or_not=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 68 False Posive: 297 False Negative: 230\n",
      "COCO AP@[.5:.95]: 0.0151\n",
      "Final Precision = 0.18630136986301393,\n",
      "Final Recall =0.22818791946308747,\n",
      "Final F1-Score = 0.2051282051282056\n",
      "\n",
      "Highest Precision = 0.21951219512195144,\n",
      "Highest Recall =0.2520000000000002,\n",
      "Highest F1-Score = 0.23463687150838033\n"
     ]
    }
   ],
   "source": [
    "functions.final_evaluate(metric_fn, result_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value | Value | Value | Value\n",
    "| --- | --- | --- | --- | ---\n",
    "| model | 3D-CNN | SOFTNet | SOFTNet (generator) | SOFTNet (dev)\n",
    "| epochs | | 10 | 20 | 20 (252 m)\n",
    "| batch_size | | 48 | 48 | 48\n",
    "| learning_rate | | 0.0005 | 0.0005 | 0.0005\n",
    "| True Positive | | 90 | 95 | 83\n",
    "| False Positive | | 357 | 357 | 316\n",
    "| False Negative | | 210 | 203 | 215\n",
    "| Precision | | 0.0213 | 0.2102 | 0.2080\n",
    "| Recall | | 0.3000 | 0.3188 | 0.2785\n",
    "| F1-Score | 0.2145 | 0.2410 | 0.2533 | 0.2381\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value | Value\n",
    "| --- | --- | ---\n",
    "| model | ViT (generator) | Vit (dev)\n",
    "| epochs | 20 | 20\n",
    "| batch_size | 48 | 96\n",
    "| learning_rate | 0.0005 | 0.0005\n",
    "| True Positive | 57 | 50\n",
    "| False Positive | 520 | 519\n",
    "| False Negative | 241 | 248\n",
    "| Precision | 0.0987 | 0.0878\n",
    "| Recall | 0.1912 | 0.1677\n",
    "| F1-Score | 0.1302 | 0.1153\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value |\n",
    "| --- | --- | \n",
    "| model | SL-ViT |\n",
    "| epochs | 20 (721 m) |\n",
    "| batch_size | 96 |\n",
    "| learning_rate | 0.0005 |\n",
    "| True Positive | 48 |\n",
    "| False Positive | 269 |\n",
    "| False Negative | 250 |\n",
    "| Precision | 0.1514 |\n",
    "| Recall | 0.1610 |\n",
    "| F1-Score | 0.1560 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value | Value | Value | Value\n",
    "| --- | --- | --- | --- | ---\n",
    "| model | SL-Swin-S | SL-Swin-S | SL-Swin-S | SL-Swin-S\n",
    "| epochs | 25 (6495 m) | 20 (3784 m) | 25 (4682) | 20 (2690 m)\n",
    "| batch_size | 32 | 48 | 48 | 96\n",
    "| learning_rate | 0.0005 | 0.0005 | 0.0005 | 0.0005\n",
    "| True Positive | 69 | 66 | 69 | 68\n",
    "| False Positive | 281 | 271 | 262 | 297\n",
    "| False Negative | 229 | 232 | 229 | 230\n",
    "| Precision | 0.1971 | 0.1958 | 0.2084 | 0.1863\n",
    "| Recall | 0.2315 | 0.2214 | 0.2315 | 0.2281\n",
    "| F1-Score | 0.2129 | 0.2078 | 0.2194 | 0.2051\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " p | TP | FP | FN | Precision | Recall | F1-Score\n",
      "0.05 | 163 | 2593 | 135 | 0.0591 | 0.5470 | 0.1067 |\n",
      "0.10 | 149 | 1842 | 149 | 0.0748 | 0.5000 | 0.1302 |\n",
      "0.15 | 138 | 1387 | 160 | 0.0905 | 0.4631 | 0.1514 |\n",
      "0.20 | 125 | 1079 | 173 | 0.1038 | 0.4195 | 0.1664 |\n",
      "0.25 | 114 | 854 | 184 | 0.1178 | 0.3826 | 0.1801 |\n",
      "0.30 | 108 | 703 | 190 | 0.1332 | 0.3624 | 0.1948 |\n",
      "0.35 | 96 | 590 | 202 | 0.1399 | 0.3221 | 0.1951 |\n",
      "0.40 | 89 | 488 | 209 | 0.1542 | 0.2987 | 0.2034 |\n",
      "0.45 | 81 | 413 | 217 | 0.1640 | 0.2718 | 0.2045 |\n",
      "0.50 | 71 | 342 | 227 | 0.1719 | 0.2383 | 0.1997 |\n",
      "0.55 | 68 | 297 | 230 | 0.1863 | 0.2282 | 0.2051 |\n",
      "0.60 | 60 | 265 | 238 | 0.1846 | 0.2013 | 0.1926 |\n",
      "0.65 | 47 | 214 | 251 | 0.1801 | 0.1577 | 0.1682 |\n",
      "0.70 | 36 | 177 | 262 | 0.1690 | 0.1208 | 0.1409 |\n",
      "0.75 | 32 | 147 | 266 | 0.1788 | 0.1074 | 0.1342 |\n",
      "0.80 | 31 | 122 | 267 | 0.2026 | 0.1040 | 0.1375 |\n",
      "0.85 | 26 | 104 | 272 | 0.2000 | 0.0872 | 0.1215 |\n",
      "0.90 | 21 | 88 | 277 | 0.1927 | 0.0705 | 0.1032 |\n",
      "0.95 | 20 | 83 | 278 | 0.1942 | 0.0671 | 0.0998 |\n"
     ]
    }
   ],
   "source": [
    "ablation_dict = functions.ablation_study_p_dev(\n",
    "    preds,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    "    clean_videos_images,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_code,\n",
    "    k,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6696e3028ae55fa5be357812587f73779dfb157cc851dab91c4ca8ffd3c7a806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
