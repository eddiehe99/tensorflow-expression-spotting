{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "import _pickle\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from __utils__ import images_processing\n",
    "from __utils__ import labels_processing\n",
    "from __utils__ import labeling\n",
    "from __utils__ import features_processing\n",
    "from __utils__ import loso_preparing\n",
    "from __utils__ import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"D:/Databases/CAS(ME)^2\"\n",
    "# dataset_dir = \"F:/HEH/Databases/CAS(ME)^2\"\n",
    "# dataset_dir = \"/data/disk1/heh/databases/CAS(ME)^2\"\n",
    "\n",
    "# dataset_dir = \"D:/Databases/SAMM_longvideos\"\n",
    "# dataset_dir = \"F:/HEH/Databases/SAMM_longvideos\"\n",
    "# dataset_dir = \"/data/disk1/heh/databases/SAMM_longvideos\"\n",
    "\n",
    "test_dataset_dir = \"D:/Databases/MEGC2022_testSet/CAS_Test_cropped\"\n",
    "# test_dataset_dir = \"F:/HEH/Databases/MEGC2022_testSet/CAS_Test_cropped\"\n",
    "# test_dataset_dir = \"/data/disk1/heh/databases/MEGC2022_testSet/CAS_Test_cropped\"\n",
    "\n",
    "# test_dataset_dir = \"D:/Databases/MEGC2022_testSet/SAMM_Test_cropped\"\n",
    "# test_dataset_dir = \"F:/HEH/Databases/MEGC2022_testSet/SAMM_Test_cropped\"\n",
    "# test_dataset_dir = \"/data/disk1/heh/databases/MEGC2022_testSet/SAMM_Test_cropped\"\n",
    "\n",
    "images_loading = False\n",
    "image_size = 128\n",
    "load_cropped_images = False\n",
    "# expression_type = \"mae\"  # macro-expression spotting\n",
    "expression_type = \"me\"  # micro-expression spotting\n",
    "save_x = False\n",
    "debug_preds = True\n",
    "labeling_function = \"pseudo_labeling\"\n",
    "# labeling_function = \"original_labeling\"\n",
    "model_names = {\n",
    "    0: \"SOFTNet\",\n",
    "    1: \"SOFTNetCBAM\",\n",
    "    2: \"ViT-B\",\n",
    "    3: \"SL-ViT-B\",\n",
    "    4: \"Swin-T\",\n",
    "    5: \"Swin-S\",\n",
    "    6: \"L-Swin-T\",\n",
    "    7: \"S-Swin-T\",\n",
    "    8: \"SL-Swin-T\",\n",
    "    9: \"SL-Swin-S\",\n",
    "}\n",
    "batch_size = 48\n",
    "epochs = 25\n",
    "save_preds = False\n",
    "\n",
    "mae_model_name = model_names[8]\n",
    "mae_preds_stem = (\n",
    "    f\"mae_\"\n",
    "    + mae_model_name.lower().replace(\"-\", \"_\")\n",
    "    + f\"_batch_size_{batch_size}\"\n",
    "    + f\"_epochs_{epochs}\"\n",
    "    + f\"_{labeling_function}\"\n",
    "    + f\"_{image_size}\"\n",
    "    # + \"_1\"\n",
    ")\n",
    "mae_preds_path = Path(dataset_dir, \"preds\", mae_preds_stem).with_suffix(\".pkl\")\n",
    "print(f\"mae_preds_path: {mae_preds_path}\")\n",
    "\n",
    "me_model_name = model_names[8]\n",
    "me_preds_stem = (\n",
    "    f\"me_\"\n",
    "    + me_model_name.lower().replace(\"-\", \"_\")\n",
    "    + f\"_batch_size_{batch_size}\"\n",
    "    + f\"_epochs_{epochs}\"\n",
    "    + f\"_{labeling_function}\"\n",
    "    + f\"_{image_size}\"\n",
    "    # + \"_3\"\n",
    ")\n",
    "me_preds_path = Path(dataset_dir, \"preds\", me_preds_stem).with_suffix(\".pkl\")\n",
    "print(f\"me_preds_path: {me_preds_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When debug the image processing, the videos_images is from cropped_rawpic, whereas the other variables are from rawpic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  s15\n",
      "subject:  s16\n",
      "subject:  s19\n",
      "subject:  s20\n",
      "subject:  s21\n",
      "subject:  s22\n",
      "subject:  s23\n",
      "subject:  s24\n",
      "subject:  s25\n",
      "subject:  s26\n",
      "subject:  s27\n",
      "subject:  s29\n",
      "subject:  s30\n",
      "subject:  s31\n",
      "subject:  s32\n",
      "subject:  s33\n",
      "subject:  s34\n",
      "subject:  s35\n",
      "subject:  s36\n",
      "subject:  s37\n",
      "subject:  s38\n",
      "subject:  s40\n"
     ]
    }
   ],
   "source": [
    "videos_images, subjects, subjects_videos_code = images_processing.load_images(\n",
    "    dataset_dir, images_loading=images_loading, image_size=image_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects: ['s15', 's16', 's19', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's29', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's40']\n",
      "subjects_videos_code: [['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0508'], ['0101', '0102', '0401', '0402', '0502', '0505', '0507'], ['0102', '0402', '0505', '0507', '0502'], ['0502'], ['0101', '0401'], ['0101', '0102', '0402', '0503', '0508'], ['0102', '0402', '0503', '0507'], ['0101', '0401', '0402', '0502', '0507'], ['0101', '0102', '0502', '0508'], ['0101', '0102', '0401', '0503'], ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507', '0508'], ['0502'], ['0101', '0102', '0401', '0502', '0503', '0505', '0507'], ['0101', '0401', '0402', '0502', '0503', '0505', '0507'], ['0101', '0102', '0401', '0402', '0502', '0503', '0505', '0507', '0508'], ['0102', '0402'], ['0401', '0402', '0503'], ['0102'], ['0401', '0505'], ['0101', '0402', '0502', '0505', '0507', '0508'], ['0502', '0507'], ['0401', '0502', '0503']]\n"
     ]
    }
   ],
   "source": [
    "print(\"subjects:\", subjects)\n",
    "print(\"subjects_videos_code:\", subjects_videos_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>video_name_&amp;_expression_number</th>\n",
       "      <th>onset</th>\n",
       "      <th>apex</th>\n",
       "      <th>offset</th>\n",
       "      <th>AUs</th>\n",
       "      <th>extimated_emotion</th>\n",
       "      <th>expression_type</th>\n",
       "      <th>self-reported_emotion</th>\n",
       "      <th>video_name</th>\n",
       "      <th>video_code</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anger1_1</td>\n",
       "      <td>557</td>\n",
       "      <td>572</td>\n",
       "      <td>608</td>\n",
       "      <td>4+10+14+15</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger1</td>\n",
       "      <td>0401</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anger1_2</td>\n",
       "      <td>2854</td>\n",
       "      <td>2862</td>\n",
       "      <td>2871</td>\n",
       "      <td>38</td>\n",
       "      <td>others</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>sadness</td>\n",
       "      <td>anger1</td>\n",
       "      <td>0401</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>anger2_1</td>\n",
       "      <td>2155</td>\n",
       "      <td>2163</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger2</td>\n",
       "      <td>0402</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>anger2_2</td>\n",
       "      <td>3363</td>\n",
       "      <td>3371</td>\n",
       "      <td>3383</td>\n",
       "      <td>4+7+14</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger2</td>\n",
       "      <td>0402</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>anger2_3</td>\n",
       "      <td>3380</td>\n",
       "      <td>3386</td>\n",
       "      <td>3407</td>\n",
       "      <td>4+14+38</td>\n",
       "      <td>negative</td>\n",
       "      <td>macro-expression</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger2</td>\n",
       "      <td>0402</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant video_name_&_expression_number  onset  apex  offset  \\\n",
       "0            1                       anger1_1    557   572     608   \n",
       "1            1                       anger1_2   2854  2862    2871   \n",
       "2            1                       anger2_1   2155  2163       0   \n",
       "3            1                       anger2_2   3363  3371    3383   \n",
       "4            1                       anger2_3   3380  3386    3407   \n",
       "\n",
       "          AUs extimated_emotion   expression_type self-reported_emotion  \\\n",
       "0  4+10+14+15          negative  macro-expression                 anger   \n",
       "1          38            others  macro-expression               sadness   \n",
       "2         NaN          negative  macro-expression                 anger   \n",
       "3      4+7+14          negative  macro-expression                 anger   \n",
       "4     4+14+38          negative  macro-expression                 anger   \n",
       "\n",
       "  video_name video_code subject  \n",
       "0     anger1       0401     s15  \n",
       "1     anger1       0401     s15  \n",
       "2     anger2       0402     s15  \n",
       "3     anger2       0402     s15  \n",
       "4     anger2       0402     s15  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_data = labels_processing.load_excel(dataset_dir)\n",
    "Excel_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ground Truth Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_videos_index:  [1, 4, 8, 9, 12, 13, 14, 16, 28, 33, 36, 37, 38, 45, 46, 47, 49, 50, 52, 54, 55, 57, 62, 64, 67, 71, 73, 74, 77, 83, 87, 91, 93]\n",
      "len(clean_videos_images) = 33\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    mae_clean_videos_images,\n",
    "    mae_clean_subjects_videos_code,\n",
    "    mae_clean_subjects,\n",
    "    mae_clean_subjects_videos_ground_truth_labels,\n",
    ") = labels_processing.load_ground_truth_labels(\n",
    "    dataset_dir,\n",
    "    \"mae\",\n",
    "    videos_images,\n",
    "    subjects_videos_code,\n",
    "    subjects,\n",
    "    Excel_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(clean_subjects):  14\n",
      "clean_subjects:  ['s15' 's16' 's19' 's23' 's24' 's25' 's27' 's29' 's30' 's31' 's32' 's35'\n",
      " 's37' 's38']\n",
      "len(clean_subjects_videos_code):  14\n",
      "clean_subjects_videos_codes:  [['0102', '0502'], ['0101', '0102', '0502', '0505', '0507'], ['0402'], ['0102'], ['0401', '0507'], ['0101', '0102'], ['0101', '0102', '0401', '0502', '0503', '0507'], ['0502'], ['0101', '0401'], ['0101', '0402', '0505'], ['0401', '0502', '0503', '0508'], ['0102'], ['0402', '0508'], ['0507']]\n",
      "len(clean_subjects_videos_ground_truth_labels):  14\n",
      "clean_subjects_videos_ground_truth_labels:  [[[[698, 706]], [[137, 147]]], [[[551, 564]], [[269, 277]], [[322, 333]], [[395, 406], [1694, 1709], [1879, 1894]], [[1957, 1967], [2284, 2294]]], [[[1926, 1941]]], [[[330, 345], [525, 539], [726, 739]]], [[[607, 620], [962, 976], [1889, 1901], [2180, 2192], [3440, 3452]], [[1835, 1847], [1950, 1964], [3232, 3247]]], [[[112, 126]], [[995, 1007], [1007, 1016], [1017, 1033]]], [[[873, 887]], [[33, 47], [308, 316], [373, 387]], [[351, 364], [368, 381], [1134, 1146], [1973, 1985]], [[612, 627]], [[418, 431]], [[875, 889]]], [[[139, 151]]], [[[1454, 1465]], [[925, 940]]], [[[1420, 1432]], [[1688, 1701], [2189, 2203], [2376, 2388], [3802, 3814]], [[1045, 1058]]], [[[267, 277]], [[310, 323], [1170, 1183]], [[257, 271], [1030, 1043]], [[285, 300]]], [[[99, 112], [362, 370]]], [[[3501, 3513]], [[417, 429]]], [[[2231, 2246]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"len(mae_clean_subjects): \", len(mae_clean_subjects))\n",
    "print(\"mae_clean_subjects: \", mae_clean_subjects)\n",
    "print(\"len(mae_clean_subjects_videos_code): \", len(mae_clean_subjects_videos_code))\n",
    "print(\"mae_clean_subjects_videos_codes: \", mae_clean_subjects_videos_code)\n",
    "print(\n",
    "    \"len(mae_clean_subjects_videos_ground_truth_labels): \",\n",
    "    len(mae_clean_subjects_videos_ground_truth_labels),\n",
    ")\n",
    "print(\n",
    "    \"mae_clean_subjects_videos_ground_truth_labels: \",\n",
    "    mae_clean_subjects_videos_ground_truth_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    me_clean_videos_images,\n",
    "    me_clean_subjects_videos_code,\n",
    "    me_clean_subjects,\n",
    "    me_clean_subjects_videos_ground_truth_labels,\n",
    ") = labels_processing.load_ground_truth_labels(\n",
    "    dataset_dir,\n",
    "    \"me\",\n",
    "    videos_images,\n",
    "    subjects_videos_code,\n",
    "    subjects,\n",
    "    Excel_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(me_clean_subjects): \", len(me_clean_subjects))\n",
    "print(\"me_clean_subjects: \", me_clean_subjects)\n",
    "print(\"len(me_clean_subjects_videos_code): \", len(me_clean_subjects_videos_code))\n",
    "print(\"me_clean_subjects_videos_codes: \", me_clean_subjects_videos_code)\n",
    "print(\n",
    "    \"len(me_clean_subjects_videos_ground_truth_labels): \",\n",
    "    len(me_clean_subjects_videos_ground_truth_labels),\n",
    ")\n",
    "print(\n",
    "    \"me_clean_subjects_videos_ground_truth_labels: \",\n",
    "    me_clean_subjects_videos_ground_truth_labels,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate `k`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k (Half of average length of expression) =  6\n"
     ]
    }
   ],
   "source": [
    "k = labels_processing.calculate_k(clean_subjects_videos_ground_truth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_k = labels_processing.calculate_k(mae_clean_subjects_videos_ground_truth_labels)\n",
    "me_k = labels_processing.calculate_k(me_clean_subjects_videos_ground_truth_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 3, 4])\n",
    "b = 3\n",
    "c = np.intersect1d(a, b)\n",
    "print(len(c))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for LOSO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 70 False Posive: 268 False Negative: 228\n",
      "Precision = 0.20710059171597656, Recall =0.23489932885906062, F1-Score = 0.22012578616352244\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "epsilon = sys.float_info.epsilon\n",
    "\n",
    "scenarios = {\n",
    "    0: {\n",
    "        \"dataset\": \"CAS(ME)^2\",\n",
    "        \"expression_type\": \"me\",\n",
    "        \"num_expression\": 57,\n",
    "    },\n",
    "    1: {\n",
    "        \"dataset\": \"CAS(ME)^2\",\n",
    "        \"expression_type\": \"mae\",\n",
    "        \"num_expression\": 298,\n",
    "    },\n",
    "}\n",
    "\n",
    "scenario = scenarios[1]\n",
    "true_positive = 70\n",
    "false_positive = 268\n",
    "false_negative = scenario[\"num_expression\"] - true_positive\n",
    "print(\n",
    "    f\"True Positive: {true_positive} False Posive: {false_positive} False Negative: {false_negative}\"\n",
    ")\n",
    "# add epsilon to avoid float division by zero\n",
    "precision = true_positive / (true_positive + false_positive) + epsilon\n",
    "recall = true_positive / (true_positive + false_negative) + epsilon\n",
    "F1_score = (2 * precision * recall) / (precision + recall) + epsilon\n",
    "print(f\"Precision = {precision}, Recall ={recall}, F1-Score = {F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mae_preds_path, \"rb\") as pkl_file:\n",
    "    mae_preds = _pickle.load(pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(me_preds_path, \"rb\") as pkl_file:\n",
    "    me_preds = _pickle.load(pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 is in process.\n",
      "0 video(s) have been processed.\n",
      "The current video be processed: subject s15, video 0102\n",
      "The current video be processed: subject s15, video 0502\n",
      "\n",
      "True Positive: 0 False Posive: 9 False Negative: 2\n",
      "Precision = 2.220446049250313e-16, Recall =2.220446049250313e-16, F1-Score = 4.440892098500626e-16\n",
      "Split 0 is processed.\n",
      "\n",
      "Split 1 is in process.\n",
      "2 video(s) have been processed.\n",
      "The current video be processed: subject s16, video 0101\n",
      "The current video be processed: subject s16, video 0102\n",
      "The current video be processed: subject s16, video 0502\n",
      "The current video be processed: subject s16, video 0505\n",
      "The current video be processed: subject s16, video 0507\n",
      "\n",
      "True Positive: 1 False Posive: 42 False Negative: 9\n",
      "Precision = 0.023255813953488594, Recall =0.10000000000000023, F1-Score = 0.0377358490566043\n",
      "Split 1 is processed.\n",
      "\n",
      "Split 2 is in process.\n",
      "7 video(s) have been processed.\n",
      "The current video be processed: subject s19, video 0402\n",
      "\n",
      "True Positive: 2 False Posive: 52 False Negative: 9\n",
      "Precision = 0.03703703703703726, Recall =0.18181818181818205, F1-Score = 0.061538461538462076\n",
      "Split 2 is processed.\n",
      "\n",
      "Split 3 is in process.\n",
      "8 video(s) have been processed.\n",
      "The current video be processed: subject s23, video 0102\n",
      "\n",
      "True Positive: 3 False Posive: 79 False Negative: 11\n",
      "Precision = 0.036585365853658756, Recall =0.2142857142857145, F1-Score = 0.06250000000000056\n",
      "Split 3 is processed.\n",
      "\n",
      "Split 4 is in process.\n",
      "9 video(s) have been processed.\n",
      "The current video be processed: subject s24, video 0401\n",
      "The current video be processed: subject s24, video 0507\n",
      "\n",
      "True Positive: 4 False Posive: 94 False Negative: 18\n",
      "Precision = 0.040816326530612464, Recall =0.18181818181818205, F1-Score = 0.0666666666666672\n",
      "Split 4 is processed.\n",
      "\n",
      "Split 5 is in process.\n",
      "11 video(s) have been processed.\n",
      "The current video be processed: subject s25, video 0101\n",
      "The current video be processed: subject s25, video 0102\n",
      "\n",
      "True Positive: 7 False Posive: 122 False Negative: 19\n",
      "Precision = 0.05426356589147309, Recall =0.26923076923076944, F1-Score = 0.09032258064516183\n",
      "Split 5 is processed.\n",
      "\n",
      "Split 6 is in process.\n",
      "13 video(s) have been processed.\n",
      "The current video be processed: subject s27, video 0101\n",
      "The current video be processed: subject s27, video 0102\n",
      "The current video be processed: subject s27, video 0401\n",
      "The current video be processed: subject s27, video 0502\n",
      "The current video be processed: subject s27, video 0503\n",
      "The current video be processed: subject s27, video 0507\n",
      "\n",
      "True Positive: 13 False Posive: 155 False Negative: 24\n",
      "Precision = 0.0773809523809526, Recall =0.3513513513513516, F1-Score = 0.12682926829268346\n",
      "Split 6 is processed.\n",
      "\n",
      "Split 7 is in process.\n",
      "19 video(s) have been processed.\n",
      "The current video be processed: subject s29, video 0502\n",
      "\n",
      "True Positive: 13 False Posive: 176 False Negative: 25\n",
      "Precision = 0.068783068783069, Recall =0.34210526315789497, F1-Score = 0.11453744493392123\n",
      "Split 7 is processed.\n",
      "\n",
      "Split 8 is in process.\n",
      "20 video(s) have been processed.\n",
      "The current video be processed: subject s30, video 0101\n",
      "The current video be processed: subject s30, video 0401\n",
      "\n",
      "True Positive: 13 False Posive: 228 False Negative: 27\n",
      "Precision = 0.05394190871369317, Recall =0.32500000000000023, F1-Score = 0.09252669039145965\n",
      "Split 8 is processed.\n",
      "\n",
      "Split 9 is in process.\n",
      "22 video(s) have been processed.\n",
      "The current video be processed: subject s31, video 0101\n",
      "The current video be processed: subject s31, video 0402\n",
      "The current video be processed: subject s31, video 0505\n",
      "\n",
      "True Positive: 14 False Posive: 242 False Negative: 32\n",
      "Precision = 0.05468750000000022, Recall =0.30434782608695676, F1-Score = 0.09271523178808003\n",
      "Split 9 is processed.\n",
      "\n",
      "Split 10 is in process.\n",
      "25 video(s) have been processed.\n",
      "The current video be processed: subject s32, video 0401\n",
      "The current video be processed: subject s32, video 0502\n",
      "The current video be processed: subject s32, video 0503\n",
      "The current video be processed: subject s32, video 0508\n",
      "\n",
      "True Positive: 16 False Posive: 288 False Negative: 36\n",
      "Precision = 0.05263157894736864, Recall =0.30769230769230793, F1-Score = 0.08988764044943875\n",
      "Split 10 is processed.\n",
      "\n",
      "Split 11 is in process.\n",
      "29 video(s) have been processed.\n",
      "The current video be processed: subject s35, video 0102\n",
      "\n",
      "True Positive: 17 False Posive: 293 False Negative: 37\n",
      "Precision = 0.05483870967741958, Recall =0.31481481481481505, F1-Score = 0.09340659340659395\n",
      "Split 11 is processed.\n",
      "\n",
      "Split 12 is in process.\n",
      "30 video(s) have been processed.\n",
      "The current video be processed: subject s37, video 0402\n",
      "The current video be processed: subject s37, video 0508\n",
      "\n",
      "True Positive: 17 False Posive: 341 False Negative: 39\n",
      "Precision = 0.04748603351955329, Recall =0.30357142857142877, F1-Score = 0.08212560386473486\n",
      "Split 12 is processed.\n",
      "\n",
      "Split 13 is in process.\n",
      "32 video(s) have been processed.\n",
      "The current video be processed: subject s38, video 0507\n",
      "\n",
      "True Positive: 17 False Posive: 363 False Negative: 40\n",
      "Precision = 0.04473684210526338, Recall =0.2982456140350879, F1-Score = 0.07780320366132781\n",
      "Split 13 is processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The 100-threads method is almost as fast as the 10-threads method.\n",
    "\"\"\"\n",
    "\n",
    "mae_ablation_dict = {\n",
    "    \"p\": [],\n",
    "    \"true_positive\": [],\n",
    "    \"false_positive\": [],\n",
    "    \"false_negative\": [],\n",
    "    \"expression_count\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"F1_score\": [],\n",
    "}\n",
    "me_ablation_dict = {\n",
    "    \"p\": [],\n",
    "    \"true_positive\": [],\n",
    "    \"false_positive\": [],\n",
    "    \"false_negative\": [],\n",
    "    \"expression_count\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"F1_score\": [],\n",
    "}\n",
    "\n",
    "print(\" p | TP | FP | FN | Precision | Recall | F1-Score\")\n",
    "p_arange = np.arange(0.01, 1.0, 0.01)\n",
    "mae_dict_queues = []\n",
    "mae_threads = []\n",
    "me_dict_queues = []\n",
    "me_threads = []\n",
    "for _ in p_arange:\n",
    "    mae_dict_queues.append(Queue())\n",
    "    me_dict_queues.append(Queue())\n",
    "\n",
    "for p_index, p in enumerate(p_arange):\n",
    "    # mae\n",
    "    mae_thread = threading.Thread(\n",
    "        target=functions.multithread_spot_and_evaluate,\n",
    "        args=(\n",
    "            mae_preds,\n",
    "            mae_clean_subjects_videos_ground_truth_labels,\n",
    "            mae_clean_videos_images,\n",
    "            mae_clean_subjects,\n",
    "            mae_clean_subjects_videos_code,\n",
    "            mae_k,\n",
    "            p,\n",
    "            mae_dict_queues[p_index],\n",
    "        ),\n",
    "    )\n",
    "    mae_thread.start()\n",
    "    mae_threads.append(mae_thread)\n",
    "\n",
    "    # me\n",
    "    me_thread = threading.Thread(\n",
    "        target=functions.multithread_spot_and_evaluate,\n",
    "        args=(\n",
    "            me_preds,\n",
    "            me_clean_subjects_videos_ground_truth_labels,\n",
    "            me_clean_videos_images,\n",
    "            me_clean_subjects,\n",
    "            me_clean_subjects_videos_code,\n",
    "            me_k,\n",
    "            p,\n",
    "            me_dict_queues[p_index],\n",
    "        ),\n",
    "    )\n",
    "    me_thread.start()\n",
    "    me_threads.append(me_thread)\n",
    "    for mae_thread, me_thread in zip(mae_threads, me_threads):\n",
    "        mae_thread.join()\n",
    "        me_thread.join()\n",
    "    print(f\" p: {p}\", end=\"\\r\")\n",
    "\n",
    "# Attention!!!\n",
    "# Different loop sequence\n",
    "for p_index, p in enumerate(p_arange):\n",
    "    # mae\n",
    "    mae_p_segment_matrix = mae_dict_queues[p_index].get()\n",
    "    mae_ablation_dict[\"p\"] += mae_p_segment_matrix[\"p\"]\n",
    "    mae_ablation_dict[\"true_positive\"] += mae_p_segment_matrix[\"true_positive\"]\n",
    "    mae_ablation_dict[\"false_positive\"] += mae_p_segment_matrix[\"false_positive\"]\n",
    "    mae_ablation_dict[\"false_negative\"] += mae_p_segment_matrix[\"false_negative\"]\n",
    "    mae_ablation_dict[\"expression_count\"] += mae_p_segment_matrix[\"expression_count\"]\n",
    "    mae_ablation_dict[\"precision\"] += mae_p_segment_matrix[\"precision\"]\n",
    "    mae_ablation_dict[\"recall\"] += mae_p_segment_matrix[\"recall\"]\n",
    "    mae_ablation_dict[\"F1_score\"] += mae_p_segment_matrix[\"F1_score\"]\n",
    "\n",
    "    # me\n",
    "    me_p_segment_matrix = me_dict_queues[p_index].get()\n",
    "    me_ablation_dict[\"p\"] += me_p_segment_matrix[\"p\"]\n",
    "    me_ablation_dict[\"true_positive\"] += me_p_segment_matrix[\"true_positive\"]\n",
    "    me_ablation_dict[\"false_positive\"] += me_p_segment_matrix[\"false_positive\"]\n",
    "    me_ablation_dict[\"false_negative\"] += me_p_segment_matrix[\"false_negative\"]\n",
    "    me_ablation_dict[\"expression_count\"] += me_p_segment_matrix[\"expression_count\"]\n",
    "    me_ablation_dict[\"precision\"] += me_p_segment_matrix[\"precision\"]\n",
    "    me_ablation_dict[\"recall\"] += me_p_segment_matrix[\"recall\"]\n",
    "    me_ablation_dict[\"F1_score\"] += me_p_segment_matrix[\"F1_score\"]\n",
    "\n",
    "    # overall\n",
    "    true_positive = (\n",
    "        mae_ablation_dict[\"true_positive\"][-1] + me_ablation_dict[\"true_positive\"][-1]\n",
    "    )\n",
    "    false_positive = (\n",
    "        mae_ablation_dict[\"false_positive\"][-1] + me_ablation_dict[\"false_positive\"][-1]\n",
    "    )\n",
    "    false_negative = (\n",
    "        mae_ablation_dict[\"expression_count\"][-1]\n",
    "        + me_ablation_dict[\"expression_count\"][-1]\n",
    "        - true_positive\n",
    "    )\n",
    "    precision = true_positive / (true_positive + false_positive) + epsilon\n",
    "    recall = true_positive / (true_positive + false_negative) + epsilon\n",
    "    F1_score = (2 * precision * recall) / (precision + recall) + epsilon\n",
    "    print(\n",
    "        \"{:.2f} | {} | {} | {} | {:.4f} | {:.4f} | {:.4f} |\".format(\n",
    "            p,\n",
    "            true_positive,\n",
    "            false_positive,\n",
    "            false_negative,\n",
    "            precision,\n",
    "            recall,\n",
    "            F1_score,\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6696e3028ae55fa5be357812587f73779dfb157cc851dab91c4ca8ffd3c7a806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
